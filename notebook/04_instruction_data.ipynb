{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysx/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "from docx import Document\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取docx文档\n",
    "def read_docx_file(file_path):\n",
    "    document = Document(file_path)\n",
    "    text = \"\"\n",
    "    for paragraph in document.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# 从文本中提取json部分\n",
    "def extract_json(text):\n",
    "    # 使用正则表达式匹配有效的JSON部分\n",
    "    json_pattern = r'\\{.*?\\}'\n",
    "    matches = re.findall(json_pattern, text, re.DOTALL)\n",
    "    print(len(matches))\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        return matches\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 把字符串转换成json格式\n",
    "def list_to_json(list):\n",
    "    r = []\n",
    "    for t in list:\n",
    "        j = json.loads(t)\n",
    "        r.append(j)\n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 18687.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 读取docx文档\n",
    "file_path = \"../data/docx/zysft.docx\"\n",
    "text = read_docx_file(file_path)\n",
    "\n",
    "# 提取json部分\n",
    "json_text = extract_json(text)\n",
    "\n",
    "# 转换成json list\n",
    "list = list_to_json(json_text)\n",
    "\n",
    "#转换成datasets\n",
    "dataset = Dataset.from_list(list)\n",
    "\n",
    "dataset = dataset.rename_column('instruct', 'instruction')\n",
    "\n",
    "\n",
    "#保存数据\n",
    "dataset.save_to_disk(\"../data/datasets/zysft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5468.45it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 826.95it/s]\n",
      "Generating train split: 51759 examples [00:00, 141129.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "j = dataset.from_json(\"../data/json/alpaca_data_cleaned_archive.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output', 'input'],\n",
       "    num_rows: 51759\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = concatenate_datasets([dataset, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 51859/51859 [00:00<00:00, 625033.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "combined_dataset.save_to_disk(\"../data/datasets/zysft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Generate a story describing the emotions of a character in a given situation.',\n",
       " 'input': \"Alice is stuck in traffic, trying to get to her parent's house for Thanksgiving.\",\n",
       " 'output': \"Alice pounded her fists on the steering wheel as she looked out the window at the gridlocked cars stretching on for miles. She was desperate to reach her parents' house in time for Thanksgiving, but it seemed like every driver on the road had decided to take the same route she had. Anger and frustration built within her as the minutes ticked by, feeling like hours. Her only hope was that somehow, some way, she would still make it on time.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '定义五行的生克制化规律。',\n",
       " 'input': '五行的生克制化规律是五行结构系统在正常情况下的自动调节机制。五行之间通过相生相克的关系，维持事物的平衡和发展。相生是指五行之间互相滋生和促进的关系，如木生火、火生土等。相克是指五行之间相互制约的关系，如木克土、土克水等。制化关系是生克关系的结合，生中有克、克中有生，相反相成，维持和促进事物相对平衡协调和发展变化。',\n",
       " 'output': '五行的生克制化规律是指五行相生和相克的动态平衡，其中相生规律体现为五行之间的相互滋养和促进，相克规律体现为五行之间的相互制约和克制，制化规律则是生克结合的复杂关系，确保事物的平衡发展。'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
